<!DOCTYPE html>
<html lang="es-CO">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tema 13.1 Subtema 13.1.1</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            line-height: 1.8;
            font-size: 18px;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }
        .content {
            color: #333;
            text-align: justify;
        }
        .instructions {
            background-color: #e8f4f8;
            border-left: 4px solid #3498db;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }
        .instructions h2 {
            margin-top: 0;
            color: #2980b9;
            font-size: 16px;
        }
        .instructions ol {
            margin: 10px 0;
            padding-left: 20px;
        }
        .instructions li {
            margin: 5px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Tema 13.1 Subtema 13.1.1</h1>
        
        <div class="instructions">
            <h2>üì¢ Instrucciones para escuchar con voz Salome (Colombia)</h2>
            <ol>
                <li>Haz clic derecho en esta p√°gina</li>
                <li>Selecciona <strong>"Leer en voz alta"</strong> o presiona <strong>Ctrl + Shift + U</strong></li>
                <li>En el panel de lectura, haz clic en <strong>Opciones de voz</strong> (‚öôÔ∏è)</li>
                <li>Selecciona la voz: <strong>es-CO-SalomeNeural (Colombia)</strong></li>
                <li>Ajusta la velocidad a tu preferencia</li>
                <li>Presiona <strong>Play ‚ñ∂Ô∏è</strong> para comenzar</li>
            </ol>
        </div>
        
        <div class="content">
            Guion de Video: 12-Factor App y Containerizaci√≥n Duraci√≥n total: 35 minutos Objetivo: Comprender los 12 principios de aplicaciones cloud-native y c√≥mo implementarlos con Docker --- ## Introducci√≥n [Pantalla: T√≠tulo "12-Factor App y Containerizaci√≥n"] Hola, bienvenidos. Hoy vamos a explorar los fundamentos de las aplicaciones cloud-native: los 12-Factor App principles y la containerizaci√≥n con Docker. [Visual: Transici√≥n de monolito a cloud-native] Cuando hablamos de "cloud-native", no nos referimos simplemente a "ejecutar en la nube". Se trata de un conjunto de pr√°cticas arquitecturales que garantizan: - ‚úÖ Escalabilidad el√°stica - ‚úÖ Resiliencia ante fallos - ‚úÖ Despliegue continuo - ‚úÖ Portabilidad [Visual: Logo 12-Factor + Docker] Los 12-Factor App principles, definidos por Heroku en 2011, son la base fundamental. Docker y Kubernetes son las tecnolog√≠as que materializan estos principios. Vamos a ver cada factor en detalle y c√≥mo aplicarlo con ejemplos pr√°cticos. --- ## Factor 1-2: Codebase y Dependencies [Pantalla: Factor 1 - Codebase] ### Factor 1. Un repositorio, m√∫ltiples deploys [Visual: Diagrama de un repo con m√∫ltiples branches] `` ‚úÖ BIEN: Un repo, diferentes environments Repo: myapp ‚îú‚îÄ‚îÄ main ‚Üí production ‚îú‚îÄ‚îÄ staging ‚Üí staging ‚îî‚îÄ‚îÄ develop ‚Üí development ` El mismo c√≥digo en diferentes ambientes, configurado de forma distinta. NO repositorios separados para cada environment. [Pantalla: Factor 2 - Dependencies] ### Factor 2: Declarar y aislar dependencias [Mostrar c√≥digo: package.json] `json { "name": "my-app", "engines": { "node": ">=18.0.0" }, "dependencies": { "express": "^4.18.2", "pg": "^8.11.0" } } ` [Resaltar] Todo debe estar declarado expl√≠citamente. Nada de "requiere Python 3.9 instalado en tu m√°quina" sin especificarlo en c√≥digo. [Transici√≥n a Docker] Y aqu√≠ es donde Docker brilla: `dockerfile FROM python:3.11-slim COPY requirements.txt . RUN pip install -r requirements.txt ` Aislamiento completo: las dependencias viven dentro del container, no en tu m√°quina. --- ## Factor 3: Config (El m√°s importante) [Pantalla: Factor 3 - Config] Este es probablemente el factor m√°s violado en aplicaciones legacy. [Mostrar c√≥digo: ‚ùå Anti-pattern] `javascript // ‚ùå MAL: Config hardcoded const config = { database: 'prod-db.example.com', password: 'super-secret-123' // üö® PELIGRO }; ` [Resaltar en rojo] Dos problemas graves: 1. Password en c√≥digo ‚Üí comprometido si alguien ve el repo 2. Misma config para todos ‚Üí no puedes usar esto en desarrollo [Transici√≥n: ‚úÖ Soluci√≥n] [Mostrar c√≥digo: Correcto] `typescript function loadConfig(): AppConfig { return { database: { host: requireEnv('DATABASE_HOST'), password: requireEnv('DATABASE_PASSWORD') } }; } ` [Visual: Environment variables fluyendo al container] `bash # .env.production DATABASE_HOST=prod-db.example.com DATABASE_PASSWORD=<from-secrets-manager> # .env.development DATABASE_HOST=localhost DATABASE_PASSWORD=dev-password ` Mismo c√≥digo, diferente configuraci√≥n seg√∫n el environment. [Demo: Kubernetes ConfigMap + Secret] `yaml # configmap.yaml apiVersion: v1 kind: ConfigMap data: DATABASE_HOST: "postgres-service" # secret.yaml apiVersion: v1 kind: Secret data: DATABASE_PASSWORD: cGFzc3dvcmQxMjM= # base64 ` [Resaltar] Kubernetes inyecta estas variables al container autom√°ticamente. --- ## Factor 6: Processes (Stateless) [Pantalla: Factor 6 - Processes] Principio cr√≠tico: Tu aplicaci√≥n debe ser stateless. Todo estado va en backing services. [Diagrama: Problema con estado en memoria] Imagina este c√≥digo: `javascript let sessionData = {}; // ‚ùå En memoria app.post('/login', (req, res) => { sessionData[sessionId] = { userId: '123' }; }); ` [Animaci√≥n: 3 pods en Kubernetes] ` Usuario login ‚Üí Pod 1 (crea sesi√≥n en memoria) Usuario request ‚Üí Pod 2 (no tiene la sesi√≥n) ‚ùå ` [Resaltar en rojo] Con 3 r√©plicas en Kubernetes, cada pod tiene su propia memoria. El load balancer env√≠a requests a diferentes pods ‚Üí sesi√≥n se pierde. [Transici√≥n: ‚úÖ Soluci√≥n con Redis] `typescript // ‚úÖ Session en Redis (compartido) await redis.setex(session:${sessionId}, 3600, JSON.stringify(data)); ` [Diagrama: Redis como estado compartido] ` Usuario login ‚Üí Pod 1 ‚Üí Redis (guarda sesi√≥n) Usuario request ‚Üí Pod 2 ‚Üí Redis (lee sesi√≥n) ‚úÖ ` [Resaltar en verde] Todos los pods acceden al mismo Redis ‚Üí estado consistente. [Mostrar segundo ejemplo: File uploads] `python # ‚ùå MAL: Local filesystem file.save(f'/tmp/uploads/{filename}') # ‚úÖ BIEN: S3 storage s3_client.upload_file(bucket='my-bucket', key=filename) ` [Visual: Container filesystem es ef√≠mero] Cuando un pod se reinicia, el filesystem local desaparece. S3 persiste. --- ## Factor 9: Disposability (Graceful Shutdown) [Pantalla: Factor 9 - Disposability] Tu app debe: 1. Iniciar r√°pido (segundos, no minutos) 2. Terminar gracefully (sin cortar requests) [Diagrama: Kubernetes terminando un pod] ` 1. Kubernetes env√≠a SIGTERM al pod 2. App tiene 30s para terminar 3. Si no termina, SIGKILL (forzado) ` [Mostrar c√≥digo: Sin graceful shutdown] `javascript // ‚ùå MAL: No maneja SIGTERM app.listen(3000); // Kubernetes env√≠a SIGTERM ‚Üí app ignora ‚Üí SIGKILL ‚Üí requests cortados ` [Transici√≥n: ‚úÖ Correcto] `typescript const server = app.listen(3000); process.on('SIGTERM', async () => { console.log('SIGTERM received, shutting down...'); // 1. Stop accepting new requests server.close(); // 2. Finish ongoing requests (with timeout) await Promise.race([ waitForOngoingRequests(), timeout(30000) ]); // 3. Close DB connections await database.close(); process.exit(0); }); ` [Animaci√≥n: Timeline de shutdown] ` t=0s: SIGTERM received t=1s: Server stops accepting new requests t=5s: Ongoing requests complete t=6s: Database connection closed t=6s: Process exits cleanly ‚úÖ ` [Resaltar] Sin p√©rdida de requests, sin errores para usuarios. --- ## Factor 11. Logs (Structured Logging) [Pantalla: Factor 11 - Logs] Principio: Logs son event streams, escribir a stdout/stderr. [Mostrar c√≥digo: ‚ùå Anti-pattern] `typescript // ‚ùå MAL: Log a archivo fs.appendFileSync('/var/log/app.log', message); ` [Diagrama: Problemas en Kubernetes] ` Pod 1 ‚Üí /var/log/app.log Pod 2 ‚Üí /var/log/app.log Pod 3 ‚Üí /var/log/app.log ¬øC√≥mo ves todos los logs? ‚ùå Pod se reinicia ‚Üí logs desaparecen ‚ùå ` [Transici√≥n: ‚úÖ Soluci√≥n] `typescript // ‚úÖ BIEN: Structured logging a stdout console.log(JSON.stringify({ timestamp: new Date().toISOString(), level: 'info', message: 'Order created', orderId: '123', userId: 'u456' })); ` [Visual: Flujo de logs en Kubernetes] ` Pods ‚Üí stdout ‚Üí Kubernetes ‚Üí Log Aggregator (ELK/Loki) ‚Üì Dashboard centralizado ‚úÖ ` [Demo: Query logs] `bash # Kubernetes logs (todos los pods) kubectl logs deployment/myapp --tail=100 # Loki query {app="myapp"} |= "error" | json | level="error" ` [Resaltar] Logs centralizados, buscables, persistentes. --- ## Factor 10: Dev/Prod Parity [Pantalla: Factor 10 - Dev/Prod Parity] Principio: Desarrollo y producci√≥n deben ser lo m√°s similares posible. [Diagrama: ‚ùå Anti-pattern] ` Development: Production: - SQLite - PostgreSQL - In-memory cache - Redis - Mock email - SendGrid - Windows - Linux ` [Resaltar en rojo] Diferentes bases de datos ‚Üí comportamiento diferente ‚Üí bugs en producci√≥n. [Transici√≥n: ‚úÖ Docker Compose] [Mostrar c√≥digo: docker-compose.yml] `yaml services: app: build: . environment: DATABASE_URL: postgres://postgres:5432/myapp REDIS_URL: redis://redis:6379 postgres: image: postgres:15 # Misma versi√≥n que prod redis: image: redis:7 # Misma versi√≥n que prod ` [Terminal: Ejecutar] `bash docker-compose up ` [Animaci√≥n: Levantando stack completo] ` Starting postgres... done Starting redis... done Starting app... done ‚úÖ Developer tiene exactamente lo mismo que producci√≥n ` [Resaltar] Un comando, stack completo, dev/prod identical. --- ## Docker: Multi-Stage Build [Pantalla: Dockerfile Optimizado] Ahora veamos c√≥mo Docker implementa varios de estos factores. [Mostrar c√≥digo: Dockerfile multi-stage] `dockerfile # STAGE 1. Build FROM node:18 AS builder WORKDIR /app COPY package.json ./ RUN npm ci COPY . . RUN npm run build # STAGE 2: Runtime FROM node:18-alpine RUN adduser -S nodejs -u 1001 WORKDIR /app COPY --from=builder /app/dist ./dist COPY --from=builder /app/node_modules ./node_modules USER nodejs EXPOSE 3000 CMD ["node", "dist/main.js"] ` [Diagrama: Comparaci√≥n de tama√±os] ` Builder stage: 850 MB (Node + build tools) Runtime stage: 180 MB (Node + app) ‚úÖ Reducci√≥n: 79% ` [Resaltar 3 optimizaciones clave] 1. Layer caching: `dockerfile # ‚úÖ Dependencies primero COPY package.json ./ RUN npm ci # Cache se reutiliza si package.json no cambia # C√≥digo despu√©s COPY . . ` 1. Non-root user (security): `dockerfile RUN adduser -S nodejs -u 1001 USER nodejs # No corre como root ` 1. Alpine base (imagen peque√±a): `dockerfile FROM node:18-alpine # 40MB vs node:18 (900MB) ` [Demo: Build] `bash docker build -t myapp:1.0.0 . # Ver tama√±o docker images # myapp 1.0.0 180MB ‚úÖ ` --- ## Demo: Sistema Completo [Pantalla: Arquitectura de ejemplo] Veamos c√≥mo todo esto se une en un sistema real. [Diagrama: E-commerce microservices] ` API Gateway ‚îú‚îÄ‚îÄ Product Service ‚îú‚îÄ‚îÄ Order Service ‚îî‚îÄ‚îÄ Payment Service Backing Services: - PostgreSQL (data) - Redis (cache/sessions) - RabbitMQ (events) ` [Terminal: Levantar con Docker Compose] `bash docker-compose up -d # Ver servicios docker-compose ps ` [Mostrar output] ` NAME STATUS PORTS product-service Up 0.0.0.0:3001->3001 order-service Up 0.0.0.0:3002->3002 payment-service Up 0.0.0.0:3003->3003 postgres Up (healthy) 5432 redis Up 6379 rabbitmq Up (healthy) 5672, 15672 ` [Resaltar] Todo el stack corriendo localmente, id√©ntico a producci√≥n. [Terminal: Test] `bash # Crear producto curl -X POST http://localhost:3001/products \ -H "Content-Type: application/json" \ -d '{"name":"Laptop","price":999.99}' # Crear orden curl -X POST http://localhost:3002/orders \ -d '{"userId":"u123","items":[{"productId":"p1","qty":1}]}' ` [Mostrar logs estructurados] `bash docker-compose logs -f order-service ` [Output en JSON] `json { "timestamp": "2024-01-15T10:30:00.000Z", "level": "info", "message": "Order created", "orderId": "o123", "userId": "u123" } ` [Resaltar] Logs estructurados (Factor 11) ‚úÖ [Terminal: Graceful shutdown test] `bash # Enviar SIGTERM docker-compose stop order-service ` [Mostrar logs de shutdown] ` SIGTERM received, shutting down gracefully... Closing database connections... Closing RabbitMQ connection... Shutdown complete ` [Resaltar] Graceful shutdown (Factor 9) ‚úÖ --- ## Kubernetes: Deploy a Producci√≥n [Pantalla: De Docker a Kubernetes] Ahora desplegamos a Kubernetes en producci√≥n. [Mostrar c√≥digo: deployment.yaml] `yaml apiVersion: apps/v1 kind: Deployment metadata: name: order-service spec: replicas: 3 # Factor 8: Concurrency template: spec: containers: - name: app image: order-service:1.0.0 envFrom: - configMapRef: name: app-config # Factor 3: Config - secretRef: name: app-secrets # Factor 3: Secrets livenessProbe: httpGet: path: /health port: 3002 readinessProbe: httpGet: path: /health port: 3002 terminationGracePeriodSeconds: 30 # Factor 9 ` [Terminal: Deploy] `bash kubectl apply -f deployment.yaml kubectl apply -f service.yaml kubectl apply -f hpa.yaml ` [Mostrar output] ` deployment.apps/order-service created service/order-service created horizontalpodautoscaler.autoscaling/order-service-hpa created ` [Terminal: Ver pods] `bash kubectl get pods ` ` NAME READY STATUS order-service-6d4f8c9b7f-2kx9p 1/1 Running order-service-6d4f8c9b7f-7h5nq 1/1 Running order-service-6d4f8c9b7f-xm8wz 1/1 Running ` [Resaltar] 3 r√©plicas (Factor 8: Concurrency) ‚úÖ [Diagrama: HPA en acci√≥n] ` CPU > 70% ‚Üí Kubernetes a√±ade pods autom√°ticamente 3 pods ‚Üí 5 pods ‚Üí 8 pods CPU < 70% ‚Üí Reduce pods 8 pods ‚Üí 5 pods ‚Üí 3 pods ` [Resaltar] Escalado autom√°tico basado en demanda. --- ## Resumen y Pr√≥ximos Pasos [Pantalla: Checklist de 12-Factor] Hemos cubierto: ‚úÖ Factor 1-2: Codebase √∫nico, dependencias declaradas ‚úÖ Factor 3: Config en environment variables ‚úÖ Factor 6: Stateless con Redis/S3 ‚úÖ Factor 9: Graceful shutdown con SIGTERM ‚úÖ Factor 10: Dev/Prod parity con Docker Compose ‚úÖ Factor 11. Structured logging a stdout [Visual: Docker ‚Üí Kubernetes pipeline] ` Local Development (Docker Compose) ‚Üì Build (Multi-stage Dockerfile) ‚Üì CI/CD (GitHub Actions) ‚Üì Production (Kubernetes) `` [Pantalla: Pr√≥ximo tema] En el pr√≥ximo video exploraremos Kubernetes en profundidad: - Deployments y StatefulSets - Services y Ingress - ConfigMaps y Secrets avanzados - Observabilidad con Prometheus [Cierre] ¬°Gracias por ver! Nos vemos en el pr√≥ximo video. --- ## Recursos Visuales Necesarios 1. Diagramas: - Flujo de environment variables - Problema de estado en memoria (3 pods) - Redis como estado compartido - Timeline de graceful shutdown - Multi-stage build comparison - Arquitectura de microservices - HPA scaling animation 2. Code Highlights: - ‚ùå Anti-patterns en rojo - ‚úÖ Soluciones en verde - N√∫meros de l√≠nea importantes resaltados 3. Terminal Demos: - docker-compose up - kubectl apply - kubectl get pods - Log streaming 4. Comparaciones Lado a Lado: - Legacy vs Cloud-Native - Development vs Production - Builder vs Runtime images Total: 35 minutos de contenido denso pero pr√°ctico, con demos en vivo y ejemplos concretos.
        </div>
    </div>
</body>
</html>
